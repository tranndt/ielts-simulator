{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def clean_text_single_line(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def clean_text_multiple_line(text):\n",
    "    return re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "def clean_text_paragraph(text):\n",
    "    return re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "\n",
    "#  Completion questions\n",
    "def parse_diagram_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    question_img_path = questionTask['question_img_path'].strip()  # Most important\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_items = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Idea: Correct-answer-bassed question items. Each question item will be created for each correct answer   \n",
    "    question_items = []\n",
    "    for answer_item in correct_answer_items:\n",
    "        answer_item = answer_item.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_item)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionImgPath\": question_img_path, # Most important\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_flow_chart_completion(questionTask):\n",
    "    return parse_diagram_completion(questionTask)\n",
    "\n",
    "def parse_sentence_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_items = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Idea: Correct-answer-bassed question items. Each question item will be created for each correct answer   \n",
    "    question_items = []\n",
    "    for answer_item in correct_answer_items:\n",
    "        answer_item = answer_item.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_item)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_summary_completion():\n",
    "    pass\n",
    "\n",
    "def parse_summary_completion_word_list():\n",
    "    pass\n",
    "\n",
    "def parse_table_completion():\n",
    "    pass\n",
    "\n",
    "def parse_note_completion():\n",
    "    pass\n",
    "\n",
    "\n",
    "# Matching questions\n",
    "def parse_matching_features(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "    # question_list_of_options_lines = re.split(r'\\n+', question_list_of_options)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_option_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: A    Roger Angel\\n\\nB    Phil Rasch\n",
    "\n",
    "\n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": question_option_items, # option is a tuple but correct answer might be a string\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_matching_headings():\n",
    "    pass\n",
    "\n",
    "def parse_matching_sentence_endings():\n",
    "    pass\n",
    "\n",
    "def parse_true_false_not_given(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "\n",
    "    # Idea: Each TFNG question item contains question, list of choices (TFNG) and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": [\"TRUE\", \"FALSE\", \"NOT GIVEN\"], # Always the same\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_yes_no_not_given(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "\n",
    "    # Idea: Each TFNG question item contains question, list of choices (TFNG) and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": [\"YES\", \"NO\", \"NOT GIVEN\"], # Always the same\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "\n",
    "# Choice questions\n",
    "def parse_multiple_choice_select_one():\n",
    "    pass\n",
    "\n",
    "def parse_multiple_choice_select_many():\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reading_from_yaml(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        raw_data = yaml.safe_load(f)\n",
    "    \n",
    "    reading_info = parse_reading_info(raw_data[\"reading_info\"])\n",
    "    passage_content = parse_passage_content(raw_data[\"passage_content\"])\n",
    "    question_content = parse_question_content(raw_data[\"question_content\"])\n",
    "    return {\n",
    "        \"readingInfo\": reading_info,\n",
    "        \"passageContent\": passage_content,\n",
    "        \"questionContent\": question_content\n",
    "    }\n",
    "\n",
    "def parse_reading_info(reading_info_data):\n",
    "    return {\n",
    "        \"raedingTitle\": clean_text_single_line(reading_info_data[\"reading_title\"]),\n",
    "        \"readingSubtitle\": clean_text_single_line(reading_info_data[\"reading_subtitle\"]),\n",
    "    }\n",
    "    pass\n",
    "\n",
    "def parse_passage_content(passage_data):\n",
    "    return {\n",
    "        \"passageContext\": clean_text_single_line(passage_data[\"passage_context\"]),\n",
    "        \"passageTitle\": clean_text_single_line(passage_data[\"passage_title\"]),\n",
    "        \"passageSubtitle\": clean_text_single_line(passage_data[\"passage_subtitle\"]),\n",
    "        \"passageMainText\": clean_text_paragraph(passage_data[\"passage_main_text\"]),\n",
    "    }\n",
    "\n",
    "def parse_question_content(question_data):\n",
    "    questionTasks = []\n",
    "    for question in question_data:\n",
    "        questionTasks.append(parse_question_task(question))\n",
    "    return questionTasks\n",
    "\n",
    "def parse_question_task(questionTask):\n",
    "    parser_functions = {\n",
    "        \"multiple_choice_select_one\": parse_multiple_choice_select_one,\n",
    "        \"multiple_choice_select_many\": parse_multiple_choice_select_many,\n",
    "        \"diagram_completion\": parse_diagram_completion,\n",
    "        \"flow_chart_completion\": parse_flow_chart_completion,\n",
    "        \"summary_completion\": parse_summary_completion,\n",
    "        \"summary_completion_word_list\": parse_summary_completion_word_list,\n",
    "        \"table_completion\": parse_table_completion,\n",
    "        \"note_completion\": parse_note_completion,\n",
    "        \"matching_features\": parse_matching_features,\n",
    "        \"matching_headings\": parse_matching_headings,\n",
    "        \"matching_sentence_endings\": parse_matching_sentence_endings,\n",
    "        \"true_false_not_given\": parse_true_false_not_given,\n",
    "        \"yes_no_not_given\": parse_yes_no_not_given\n",
    "    }\n",
    "    if questionTask[\"task_type\"] not in parser_functions:\n",
    "        raise Exception(\"Invalid question type\")\n",
    "    return parser_functions[questionTask[\"task_type\"]](questionTask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_type': 'true_false_notgiven\\n',\n",
       "  'task_description': 'Questions 14-19\\nDo the following statements agree with the information given in Reading Passage 2?\\n\\nIn boxes 14-19 on your answer sheet, write\\n\\nTRUE                if the statement agrees with the information\\n\\nFALSE               if the statement contradicts the information\\n\\nNOT GIVEN     if there is no information on this\\n',\n",
       "  'question_main_title': '',\n",
       "  'question_main_text': '14   The Falkirk Wheel has linked the Forth & Clyde Canal with the Union Canal for the first time in their history.\\n\\n15   There was some opposition to the design of the Falkirk Wheel at first.\\n\\n16   The Falkirk Wheel was initially put together at the location where its components were manufactured.\\n\\n17   The Falkirk Wheel is the only boat lift in the world which has steel sections bolted together by hand.\\n\\n18   The weight of the gondolas varies according to the size of boat being carried.\\n\\n19   The construction of the Falkirk Wheel site took into account the presence of a nearby ancient monument.  \\n',\n",
       "  'question_img_path': '',\n",
       "  'question_list_title': '',\n",
       "  'question_list_of_options': '',\n",
       "  'example_answer': '',\n",
       "  'correct_answer': '14. FALSE\\n\\n15. NOT GIVEN\\n\\n16. TRUE\\n\\n17. NOT GIVEN\\n\\n18. FALSE\\n\\n19. TRUE\\n'},\n",
       " {'task_type': 'diagram_completion\\n',\n",
       "  'task_description': 'Questions 20-26\\nLabel the diagram below.\\n\\nChoose ONE WORD from the passage for each answer.\\n\\nWrite your answers in boxes 20-26 on your answer sheet.\\n',\n",
       "  'question_main_title': 'How a boat is lifted on the Falkirk Wheel\\n',\n",
       "  'question_main_text': '',\n",
       "  'question_img_path': 'https://ieltstrainingonline.com/wp-content/uploads/2020/07/11-1-2-IELTS-Reading-q14-26-980x663.jpg\\n',\n",
       "  'question_list_title': '',\n",
       "  'question_list_of_options': '',\n",
       "  'example_answer': '',\n",
       "  'correct_answer': '20. gates\\n\\n21. clamp\\n\\n22. axle\\n\\n23. cogs\\n\\n24. aqueduct\\n\\n25. wall\\n\\n26. locks'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam11_test1_1 = \"../components/assets/yaml/cam-11-test-1/cam-11-test-1-1.yaml\"\n",
    "cam11_test1_2 = \"../components/assets/yaml/cam-11-test-1/cam-11-test-1-2.yaml\"\n",
    "cam11_test1_3 = \"../components/assets/yaml/cam-11-test-1/cam-11-test-1-3.yaml\"\n",
    "cam11_test2_1 = \"../components/assets/yaml/cam-11-test-2/cam-11-test-2-1.yaml\"\n",
    "cam11_test2_2 = \"../components/assets/yaml/cam-11-test-2/cam-11-test-2-2.yaml\"\n",
    "cam11_test2_3 = \"../components/assets/yaml/cam-11-test-2/cam-11-test-2-3.yaml\"\n",
    "\n",
    "raw_data = load_yaml_file(cam11_test1_2)\n",
    "raw_data[\"question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'taskType': 'sentence_completion',\n",
       " 'taskDescription': 'Questions 1-7\\nComplete the sentences below.\\nChoose NO MORE THAN TWO WORDS from the passage for each answer.\\nWrite your answers in boxes 1-7 on your answer sheet.',\n",
       " 'questionMainTitle': 'Indoor farming',\n",
       " 'questionMainText': '1    Some food plants, including……………… are already grown indoors.\\n2    Vertical farms would be located in………………, meaning that there would be less need to take them long distances to customers.\\n3    Vertical farms could use methane from plants and animals to produce………………..\\n4    The consumption of………………… would be cut because agricultural vehicles would be unnecessary.\\n5    The fact that vertical farms would need……………….. light is a disadvantage.\\n6    One form of vertical farming involves planting in……………….. which are not fixed.\\n7    The most probable development is that food will be grown on………………… in towns and cities.',\n",
       " 'questionItems': [{'questionNumber': 1, 'correctAnswer': 'tomatoes'},\n",
       "  {'questionNumber': 2, 'correctAnswer': 'urban centres/ centers'},\n",
       "  {'questionNumber': 3, 'correctAnswer': 'energy'},\n",
       "  {'questionNumber': 4, 'correctAnswer': 'fossil fuel'},\n",
       "  {'questionNumber': 5, 'correctAnswer': 'artificial'},\n",
       "  {'questionNumber': 6, 'correctAnswer': '(stacked) trays'},\n",
       "  {'questionNumber': 7, 'correctAnswer': '(urban) rooftops'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_sentence_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_items = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Idea: Correct-answer-bassed question items. Each question item will be created for each correct answer   \n",
    "    question_items = []\n",
    "    for answer_item in correct_answer_items:\n",
    "        answer_item = answer_item.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_item)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "    \n",
    "questionTask = load_yaml_file(cam11_test1_1)[\"question\"][0]\n",
    "parse_sentence_completion(questionTask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True False Not Given & Yes No Not Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'true_false_notgiven\\n',\n",
       " 'task_description': 'Questions 8-13\\nDo the following statements agree with the information given in Reading Passage?\\n\\nIn boxes 8-13 on your answer sheet, write\\n\\nTRUE               if the statement agrees with the information\\n\\nFALSE              if the statement contradicts the information\\n\\nNOT GIVEN    if there is no information on this\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': '8   Methods for predicting the Earth’s population have recently changed.\\n\\n9   Human beings are responsible for some of the destruction to food-producing land.\\n\\n10   The crops produced in vertical farms will depend on the season.\\n\\n11   Some damage to food crops is caused by climate change.\\n\\n12   Fertilisers will be needed for certain crops in vertical farms.\\n\\n13   Vertical farming will make plants less likely to be affected by infectious diseases.\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': '',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '8. NOT GIVEN\\n\\n9. TRUE\\n\\n10. FALSE\\n\\n11. TRUE\\n\\n12. FALSE\\n\\n13. TRUE'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'true_false_notgiven',\n",
       " 'taskDescription': 'Questions 8-13\\nDo the following statements agree with the information given in Reading Passage?\\nIn boxes 8-13 on your answer sheet, write\\nTRUE               if the statement agrees with the information\\nFALSE              if the statement contradicts the information\\nNOT GIVEN    if there is no information on this',\n",
       " 'questionMainTitle': '',\n",
       " 'questionMainText': '8   Methods for predicting the Earth’s population have recently changed.\\n9   Human beings are responsible for some of the destruction to food-producing land.\\n10   The crops produced in vertical farms will depend on the season.\\n11   Some damage to food crops is caused by climate change.\\n12   Fertilisers will be needed for certain crops in vertical farms.\\n13   Vertical farming will make plants less likely to be affected by infectious diseases.',\n",
       " 'questionItems': [{'questionNumber': 8,\n",
       "   'questionText': 'Methods for predicting the Earth’s population have recently changed.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'NOT GIVEN'},\n",
       "  {'questionNumber': 9,\n",
       "   'questionText': 'Human beings are responsible for some of the destruction to food-producing land.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'TRUE'},\n",
       "  {'questionNumber': 10,\n",
       "   'questionText': 'The crops produced in vertical farms will depend on the season.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'FALSE'},\n",
       "  {'questionNumber': 11,\n",
       "   'questionText': 'Some damage to food crops is caused by climate change.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'TRUE'},\n",
       "  {'questionNumber': 12,\n",
       "   'questionText': 'Fertilisers will be needed for certain crops in vertical farms.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'FALSE'},\n",
       "  {'questionNumber': 13,\n",
       "   'questionText': 'Vertical farming will make plants less likely to be affected by infectious diseases.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'TRUE'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_true_false_not_given(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "\n",
    "    # Main content\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "\n",
    "    # Idea: Each TFNG question item contains question, list of choices (TFNG) and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": [\"TRUE\", \"FALSE\", \"NOT GIVEN\"], # Always the same\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_yes_no_not_given():\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "\n",
    "    # Idea: Each TFNG question item contains question, list of choices (TFNG) and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": [\"YES\", \"NO\", \"NOT GIVEN\"], # Always the same\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "\n",
    "questionTask = load_yaml_file(cam11_test1_1)[\"question\"][1]\n",
    "display(questionTask)\n",
    "parse_true_false_not_given(questionTask)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagram & Flow Chart Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'diagram_completion\\n',\n",
       " 'task_description': 'Questions 20-26\\nLabel the diagram below.\\n\\nChoose ONE WORD from the passage for each answer.\\n\\nWrite your answers in boxes 20-26 on your answer sheet.\\n',\n",
       " 'question_main_title': 'How a boat is lifted on the Falkirk Wheel\\n',\n",
       " 'question_main_text': '',\n",
       " 'question_img_path': 'https://ieltstrainingonline.com/wp-content/uploads/2020/07/11-1-2-IELTS-Reading-q14-26-980x663.jpg\\n',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': '',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '20. gates\\n\\n21. clamp\\n\\n22. axle\\n\\n23. cogs\\n\\n24. aqueduct\\n\\n25. wall\\n\\n26. locks'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'diagram_completion',\n",
       " 'taskDescription': 'Questions 20-26\\nLabel the diagram below.\\nChoose ONE WORD from the passage for each answer.\\nWrite your answers in boxes 20-26 on your answer sheet.',\n",
       " 'questionMainTitle': 'How a boat is lifted on the Falkirk Wheel',\n",
       " 'questionMainText': '',\n",
       " 'questionImgPath': 'https://ieltstrainingonline.com/wp-content/uploads/2020/07/11-1-2-IELTS-Reading-q14-26-980x663.jpg',\n",
       " 'questionItems': [{'questionNumber': 20, 'correctAnswer': 'gates'},\n",
       "  {'questionNumber': 21, 'correctAnswer': 'clamp'},\n",
       "  {'questionNumber': 22, 'correctAnswer': 'axle'},\n",
       "  {'questionNumber': 23, 'correctAnswer': 'cogs'},\n",
       "  {'questionNumber': 24, 'correctAnswer': 'aqueduct'},\n",
       "  {'questionNumber': 25, 'correctAnswer': 'wall'},\n",
       "  {'questionNumber': 26, 'correctAnswer': 'locks'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_diagram_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    question_img_path = questionTask['question_img_path'].strip()  # Most important\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_items = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Idea: Correct-answer-bassed question items. Each question item will be created for each correct answer   \n",
    "    question_items = []\n",
    "    for answer_item in correct_answer_items:\n",
    "        answer_item = answer_item.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_item)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionImgPath\": question_img_path, # Most important\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_flow_chart_completion(questionTask):\n",
    "    return parse_diagram_completion(questionTask)\n",
    "\n",
    "questionTask = load_yaml_file(cam11_test1_2)[\"question\"][1]\n",
    "display(questionTask)\n",
    "parse_diagram_completion(questionTask)\n",
    "# parse_true_false_not_given(questionTask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'matching_features\\n',\n",
       " 'task_description': 'Questions 37-40\\nLook at the following statements (Questions 37-40) and the list of scientists below.\\n\\nMatch each statement with the correct scientist, A-D.\\n\\nWrite the correct letter, A-D, in boxes 37-40 on your answer sheet.\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': '37   The effects of geo-engineering may not be long-lasting.\\n\\n38   Geo-engineering is a topic worth exploring.\\n\\n39   It may be necessary to limit the effectiveness of geo-engineering projects.\\n\\n40   Research into non-fossil-based fuels cannot be replaced by geo-engineering.\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': 'List of Scientists\\n',\n",
       " 'question_list_of_options': 'A    Roger Angel\\n\\nB    Phil Rasch\\n\\nC    Dan Lunt\\n\\nD    Martin Sommerkorn\\n',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '37. B\\n\\n38. D\\n\\n39. C\\n\\n40. A'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'matching_features',\n",
       " 'taskDescription': 'Questions 37-40\\nLook at the following statements (Questions 37-40) and the list of scientists below.\\nMatch each statement with the correct scientist, A-D.\\nWrite the correct letter, A-D, in boxes 37-40 on your answer sheet.',\n",
       " 'questionMainTitle': '',\n",
       " 'questionMainText': '37   The effects of geo-engineering may not be long-lasting.\\n38   Geo-engineering is a topic worth exploring.\\n39   It may be necessary to limit the effectiveness of geo-engineering projects.\\n40   Research into non-fossil-based fuels cannot be replaced by geo-engineering.',\n",
       " 'questionListTitle': 'List of Scientists',\n",
       " 'questionListOptions': [('A', 'Roger Angel'),\n",
       "  ('B', 'Phil Rasch'),\n",
       "  ('C', 'Dan Lunt'),\n",
       "  ('D', 'Martin Sommerkorn')],\n",
       " 'questionItems': [{'questionNumber': 37,\n",
       "   'questionText': 'The effects of geo-engineering may not be long-lasting.',\n",
       "   'questionOptions': [('A', 'Roger Angel'),\n",
       "    ('B', 'Phil Rasch'),\n",
       "    ('C', 'Dan Lunt'),\n",
       "    ('D', 'Martin Sommerkorn')],\n",
       "   'correctAnswer': 'B'},\n",
       "  {'questionNumber': 38,\n",
       "   'questionText': 'Geo-engineering is a topic worth exploring.',\n",
       "   'questionOptions': [('A', 'Roger Angel'),\n",
       "    ('B', 'Phil Rasch'),\n",
       "    ('C', 'Dan Lunt'),\n",
       "    ('D', 'Martin Sommerkorn')],\n",
       "   'correctAnswer': 'D'},\n",
       "  {'questionNumber': 39,\n",
       "   'questionText': 'It may be necessary to limit the effectiveness of geo-engineering projects.',\n",
       "   'questionOptions': [('A', 'Roger Angel'),\n",
       "    ('B', 'Phil Rasch'),\n",
       "    ('C', 'Dan Lunt'),\n",
       "    ('D', 'Martin Sommerkorn')],\n",
       "   'correctAnswer': 'C'},\n",
       "  {'questionNumber': 40,\n",
       "   'questionText': 'Research into non-fossil-based fuels cannot be replaced by geo-engineering.',\n",
       "   'questionOptions': [('A', 'Roger Angel'),\n",
       "    ('B', 'Phil Rasch'),\n",
       "    ('C', 'Dan Lunt'),\n",
       "    ('D', 'Martin Sommerkorn')],\n",
       "   'correctAnswer': 'A'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_matching_features(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "    # question_list_of_options_lines = re.split(r'\\n+', question_list_of_options)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_option_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: A    Roger Angel\\n\\nB    Phil Rasch\n",
    "\n",
    "\n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "questionTask = load_yaml_file(cam11_test1_3)[\"question\"][2]\n",
    "display(questionTask)\n",
    "parse_matching_features(questionTask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'table_completion\\n',\n",
       " 'task_description': 'Questions 30-36\\nComplete the table below.\\n\\nChoose ONE WORD from the passage for each answer.\\n\\nWrite your answers in boxes 30-36 on your answer sheet.\\n',\n",
       " 'question_main_title': 'GEO-ENGINEERING PROJECTS\\n',\n",
       " 'question_main_text': 'Procedure | Aim\\n\\nput a large number of tiny spacecraft into orbit far above Earth | to create a 30………….. that would reduce the amount of light reaching Earth\\n\\nplace 31…………… in the sea | to encourage 32…………… to form\\n\\nrelease aerosol sprays into the stratosphere | to create 33……………. that would reduce the amount of light reaching Earth\\n\\nfix strong 34…………… to Greenland ice sheets | to prevent icebergs moving into the sea\\n\\nplant trees in Russian Arctic that would lose their leaves in winter | to allow the 35…………… to reflect radiation\\n\\nchange the direction of 36…………… | to bring more cold water into ice-forming areas\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': '',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '30. sunshade\\n\\n31. iron\\n\\n32. algae\\n\\n33. clouds\\n\\n34. cables\\n\\n35. snow\\n\\n36. rivers  \\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questionTask = load_yaml_file(cam11_test1_3)[\"question\"][1]\n",
    "display(questionTask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
