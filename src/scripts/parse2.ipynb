{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[1, 2]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "def load_yaml_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def clean_text_single_line(text):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def clean_text_multiple_line(text):\n",
    "    new_text = re.sub(r'\\n+', '\\n', text)\n",
    "    # Clean traiiling white space at the end\n",
    "    new_text = \"\\n\".join([line.strip() for line in new_text.split('\\n')])\n",
    "    return new_text\n",
    "\n",
    "def clean_text_paragraph(text):\n",
    "    return re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "def list_AZ(start_char,end_char):\n",
    "    # List the alphabets from start_char to end_char. \n",
    "    # Ex: list_AZ('A','C') -> ['A', 'B', 'C']\n",
    "    start = ord(start_char)\n",
    "    end = ord(end_char)\n",
    "    return [chr(i) for i in range(start, end+1)]\n",
    "    \n",
    "def list_numbers(start_num, end_num):\n",
    "    # List the numbers from start_num to end_num\n",
    "    # Ex: list_numbers(1,3) -> [1, 2, 3]\n",
    "    return list(range(start_num, end_num+1))\n",
    "\n",
    "def parse_task_question_number(text):\n",
    "    range_pattern = re.compile(r'Questions (\\d+)-(\\d+)')    # Case 1: \"Questions 1-5\" (Range)\n",
    "    multiple_pattern = re.compile(r'Questions (\\d+) and (\\d+)')    # Case 2: \"Questions 1 and 2\" (Multiple)\n",
    "    single_pattern = re.compile(r'Question (\\d+)')    # Case 3: \"Question 1\" (Single)\n",
    "    # Return whichever case matches\n",
    "    if range_pattern.match(text):\n",
    "        start_num, end_num = range_pattern.match(text).groups()\n",
    "        return list_numbers(int(start_num), int(end_num))\n",
    "    elif multiple_pattern.match(text):\n",
    "        num1, num2 = multiple_pattern.match(text).groups()\n",
    "        return [int(num1), int(num2)]\n",
    "    elif single_pattern.match(text):\n",
    "        return [int(single_pattern.match(text).group(1))]\n",
    "    else:\n",
    "        raise Exception(\"Invalid question number format\")\n",
    "    \n",
    "print(parse_task_question_number(\"Questions 1-5\"))\n",
    "print(parse_task_question_number(\"Questions 1 and 2\"))\n",
    "print(parse_task_question_number(\"Question 1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Completion questions\n",
    "def parse_diagram_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    question_img_path = questionTask['question_img_path'].strip()  # Most important\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_multiple_line(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_items = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Idea: Correct-answer-bassed question items. Each question item will be created for each correct answer   \n",
    "    question_items = []\n",
    "    for answer_item in correct_answer_items:\n",
    "        answer_item = answer_item.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_item)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionImgPath\": question_img_path, # Most important\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_flow_chart_completion(questionTask):\n",
    "    return parse_diagram_completion(questionTask)\n",
    "\n",
    "def parse_sentence_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "    \n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_multiple_line(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_items = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Idea: Correct-answer-bassed question items. Each question item will be created for each correct answer   \n",
    "    question_items = []\n",
    "    for answer_item in correct_answer_items:\n",
    "        answer_item = answer_item.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_item)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_summary_completion(questionTask):\n",
    "    return parse_sentence_completion(questionTask)\n",
    "\n",
    "def parse_note_completion(questionTask):\n",
    "    return parse_sentence_completion(questionTask)\n",
    "\n",
    "def parse_summary_completion_word_list(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    question_list_of_options = clean_text_multiple_line(question_list_of_options)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    \n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    question_option_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    #  Strip items\n",
    "\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    \n",
    "    question_items = []\n",
    "    for answer_line in correct_answer_lines:\n",
    "        answer_line = answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_table_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_multiple_line(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    table_data_rows = [tuple(r.strip() for r in re.split(r'\\|',row)) for row in question_main_text_lines]\n",
    "\n",
    "\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    question_items = []\n",
    "    for answer_line in correct_answer_lines:\n",
    "        answer_line = answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": table_data_rows,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "# Matching questions\n",
    "def parse_matching_features(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_multiple_line(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "    # question_list_of_options_lines = re.split(r'\\n+', question_list_of_options)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_option_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: A    Roger Angel\\n\\nB    Phil Rasch\n",
    "\n",
    "\n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": question_option_items, # option is a tuple but correct answer might be a string\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_matching_headings(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "    # question_list_of_options_lines = re.split(r'\\n+', question_list_of_options)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_option_item_pattern = re.compile(r'([ixv]+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: A    Roger Angel\\n\\nB    Phil Rasch\n",
    "\n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_matching_sentence_endings(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    question_list_of_options = clean_text_multiple_line(question_list_of_options)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    question_option_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    #  Strip items\n",
    "\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    \n",
    "    question_items = []\n",
    "    for answer_line in correct_answer_lines:\n",
    "        answer_line = answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_matching_paragraphs(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    question_list_of_options = clean_text_multiple_line(question_list_of_options)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    start_char, end_char = re.split('-', question_list_of_options)\n",
    "    question_option_items = list_AZ(start_char, end_char)\n",
    "    #  Strip items\n",
    "\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    \n",
    "    question_items = []\n",
    "    for answer_line in correct_answer_lines:\n",
    "        answer_line = answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_true_false_not_given(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "\n",
    "    # Idea: Each TFNG question item contains question, list of choices (TFNG) and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": [\"TRUE\", \"FALSE\", \"NOT GIVEN\"], # Always the same\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_yes_no_not_given(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "\n",
    "    # Idea: Each TFNG question item contains question, list of choices (TFNG) and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": [\"YES\", \"NO\", \"NOT GIVEN\"], # Always the same\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Choice questions\n",
    "def parse_multiple_choice_select_one(questionTask):\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    mcq_question_content_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    mcq_question_option_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: A    Roger Angel\\n\\nB    Phil Rasch\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "\n",
    "    # Split items\n",
    "    multiple_choice_question_item_lines = re.split(r'\\n(?=\\d+\\s)', question_main_text) # ['27    In the secon...\\nA   the subject...\\nB   the subject...', '28    The author...\\nA   the subject...\\nB   the subject...']\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer) # ['27. A', '28. B']\n",
    "\n",
    "    question_items = []\n",
    "    for mcq_question_item_line, answer_line in zip(multiple_choice_question_item_lines, correct_answer_lines):\n",
    "        mcq_question_item_line, answer_line = mcq_question_item_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = mcq_question_content_pattern.match(mcq_question_item_line)\n",
    "        question_option_items = mcq_question_option_pattern.findall(mcq_question_item_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_multiple_choice_select_many(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'\\d+[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    question_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "    question_list_of_options_lines = re.split(r'\\n+', question_list_of_options)\n",
    "\n",
    "\n",
    "    question_items =  question_item_pattern.findall(question_list_of_options)\n",
    "    correct_answer = correct_answer_pattern.findall(correct_answer)\n",
    "\n",
    "    return {\n",
    "    \"taskType\": task_type,\n",
    "    \"taskQuestionNumberList\": task_question_number_list,\n",
    "    \"taskQuestionNumberText\": task_question_number,\n",
    "    \"taskDescription\": task_description,\n",
    "    \"questionMainTitle\": question_main_title,\n",
    "    \"questionMainText\": question_main_text,\n",
    "    \"questionItems\": question_items,\n",
    "    \"correctAnswer\": correct_answer\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reading_from_yaml(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        raw_data = yaml.safe_load(f)\n",
    "    \n",
    "    reading_info = parse_reading_info(raw_data[\"reading_info\"])\n",
    "    passage_content = parse_passage_content(raw_data[\"passage_content\"])\n",
    "    question_content = parse_question_content(raw_data[\"question_content\"])\n",
    "    return {\n",
    "        \"readingInfo\": reading_info,\n",
    "        \"passageContent\": passage_content,\n",
    "        \"questionContent\": question_content\n",
    "    }\n",
    "\n",
    "def parse_reading_info(reading_info_data):\n",
    "    return {\n",
    "        \"raedingTitle\": clean_text_single_line(reading_info_data[\"reading_title\"]),\n",
    "        \"readingSubtitle\": clean_text_single_line(reading_info_data[\"reading_subtitle\"]),\n",
    "    }\n",
    "    pass\n",
    "\n",
    "def parse_passage_content(passage_data):\n",
    "    return {\n",
    "        \"passageContext\": clean_text_single_line(passage_data[\"passage_context\"]),\n",
    "        \"passageTitle\": clean_text_single_line(passage_data[\"passage_title\"]),\n",
    "        \"passageSubtitle\": clean_text_single_line(passage_data[\"passage_subtitle\"]),\n",
    "        \"passageMainText\": clean_text_paragraph(passage_data[\"passage_main_text\"]),\n",
    "    }\n",
    "\n",
    "def parse_question_content(question_data):\n",
    "    questionTasks = []\n",
    "    for question in question_data:\n",
    "        questionTasks.append(parse_question_task(question))\n",
    "    return questionTasks\n",
    "\n",
    "def parse_question_task(questionTask):\n",
    "    parser_functions = {\n",
    "        \"multiple_choice_select_one\": parse_multiple_choice_select_one,\n",
    "        \"multiple_choice_select_many\": parse_multiple_choice_select_many,\n",
    "        \"diagram_completion\": parse_diagram_completion,\n",
    "        \"flow_chart_completion\": parse_flow_chart_completion,\n",
    "        \"summary_completion\": parse_summary_completion,\n",
    "        \"summary_completion_word_list\": parse_summary_completion_word_list,\n",
    "        \"table_completion\": parse_table_completion,\n",
    "        \"note_completion\": parse_note_completion,\n",
    "        \"matching_features\": parse_matching_features,\n",
    "        \"matching_headings\": parse_matching_headings,\n",
    "        \"matching_sentence_endings\": parse_matching_sentence_endings,\n",
    "        \"matching_paragraphs\": parse_matching_paragraphs,\n",
    "        \"true_false_not_given\": parse_true_false_not_given,\n",
    "        \"yes_no_not_given\": parse_yes_no_not_given\n",
    "    }\n",
    "    if questionTask[\"task_type\"] not in parser_functions:\n",
    "        raise Exception(\"Invalid question type\")\n",
    "    return parser_functions[questionTask[\"task_type\"]](questionTask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_type': 'true_false_notgiven\\n',\n",
       "  'task_question_number': 'Questions 14-19\\n',\n",
       "  'task_description': 'Do the following statements agree with the information given in Reading Passage 2?\\n\\nIn boxes 14-19 on your answer sheet, write\\n\\nTRUE                if the statement agrees with the information\\n\\nFALSE               if the statement contradicts the information\\n\\nNOT GIVEN     if there is no information on this\\n',\n",
       "  'question_main_title': '',\n",
       "  'question_main_text': '14   The Falkirk Wheel has linked the Forth & Clyde Canal with the Union Canal for the first time in their history.\\n\\n15   There was some opposition to the design of the Falkirk Wheel at first.\\n\\n16   The Falkirk Wheel was initially put together at the location where its components were manufactured.\\n\\n17   The Falkirk Wheel is the only boat lift in the world which has steel sections bolted together by hand.\\n\\n18   The weight of the gondolas varies according to the size of boat being carried.\\n\\n19   The construction of the Falkirk Wheel site took into account the presence of a nearby ancient monument.  \\n',\n",
       "  'question_img_path': '',\n",
       "  'question_list_title': '',\n",
       "  'question_list_of_options': '',\n",
       "  'example_answer': '',\n",
       "  'correct_answer': '14. FALSE\\n\\n15. NOT GIVEN\\n\\n16. TRUE\\n\\n17. NOT GIVEN\\n\\n18. FALSE\\n\\n19. TRUE\\n'},\n",
       " {'task_type': 'diagram_completion\\n',\n",
       "  'task_question_number': 'Questions 20-26\\n',\n",
       "  'task_description': 'Label the diagram below.\\n\\nChoose ONE WORD from the passage for each answer.\\n\\nWrite your answers in boxes 20-26 on your answer sheet.\\n',\n",
       "  'question_main_title': 'How a boat is lifted on the Falkirk Wheel\\n',\n",
       "  'question_main_text': '',\n",
       "  'question_img_path': 'https://ieltstrainingonline.com/wp-content/uploads/2020/07/11-1-2-IELTS-Reading-q14-26-980x663.jpg\\n',\n",
       "  'question_list_title': '',\n",
       "  'question_list_of_options': '',\n",
       "  'example_answer': '',\n",
       "  'correct_answer': '20. gates\\n\\n21. clamp\\n\\n22. axle\\n\\n23. cogs\\n\\n24. aqueduct\\n\\n25. wall\\n\\n26. locks'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam11_test1_1 = \"../components/assets/yaml/cam-11-test-1/cam-11-test-1-1.yaml\"\n",
    "cam11_test1_2 = \"../components/assets/yaml/cam-11-test-1/cam-11-test-1-2.yaml\"\n",
    "cam11_test1_3 = \"../components/assets/yaml/cam-11-test-1/cam-11-test-1-3.yaml\"\n",
    "cam11_test2_1 = \"../components/assets/yaml/cam-11-test-2/cam-11-test-2-1.yaml\"\n",
    "cam11_test2_2 = \"../components/assets/yaml/cam-11-test-2/cam-11-test-2-2.yaml\"\n",
    "cam11_test2_3 = \"../components/assets/yaml/cam-11-test-2/cam-11-test-2-3.yaml\"\n",
    "cam13_test2_1 = \"../components/assets/yaml/cam-13-test-2/cam-13-test-2-1.yaml\"\n",
    "cam13_test2_2 = \"../components/assets/yaml/cam-13-test-2/cam-13-test-2-2.yaml\"\n",
    "cam13_test2_3 = \"../components/assets/yaml/cam-13-test-2/cam-13-test-2-3.yaml\"\n",
    "\n",
    "raw_data = load_yaml_file(cam11_test1_2)\n",
    "raw_data[\"question\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagram & Flow Chart Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task_type': 'diagram_completion\\n',\n",
       " 'task_question_number': 'Questions 20-26\\n',\n",
       " 'task_description': 'Label the diagram below.\\n\\nChoose ONE WORD from the passage for each answer.\\n\\nWrite your answers in boxes 20-26 on your answer sheet.\\n',\n",
       " 'question_main_title': 'How a boat is lifted on the Falkirk Wheel\\n',\n",
       " 'question_main_text': '',\n",
       " 'question_img_path': 'https://ieltstrainingonline.com/wp-content/uploads/2020/07/11-1-2-IELTS-Reading-q14-26-980x663.jpg\\n',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': '',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '20. gates\\n\\n21. clamp\\n\\n22. axle\\n\\n23. cogs\\n\\n24. aqueduct\\n\\n25. wall\\n\\n26. locks'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'diagram_completion',\n",
       " 'taskQuestionNumberList': [20, 21, 22, 23, 24, 25, 26],\n",
       " 'taskQuestionNumberText': 'Questions 20-26',\n",
       " 'taskDescription': 'Label the diagram below.\\nChoose ONE WORD from the passage for each answer.\\nWrite your answers in boxes 20-26 on your answer sheet.',\n",
       " 'questionMainTitle': 'How a boat is lifted on the Falkirk Wheel',\n",
       " 'questionMainText': '',\n",
       " 'questionImgPath': 'https://ieltstrainingonline.com/wp-content/uploads/2020/07/11-1-2-IELTS-Reading-q14-26-980x663.jpg',\n",
       " 'questionItems': [{'questionNumber': 20, 'correctAnswer': 'gates'},\n",
       "  {'questionNumber': 21, 'correctAnswer': 'clamp'},\n",
       "  {'questionNumber': 22, 'correctAnswer': 'axle'},\n",
       "  {'questionNumber': 23, 'correctAnswer': 'cogs'},\n",
       "  {'questionNumber': 24, 'correctAnswer': 'aqueduct'},\n",
       "  {'questionNumber': 25, 'correctAnswer': 'wall'},\n",
       "  {'questionNumber': 26, 'correctAnswer': 'locks'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Completion questions\n",
    "def parse_diagram_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    question_img_path = questionTask['question_img_path'].strip()  # Most important\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_multiple_line(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_items = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Idea: Correct-answer-bassed question items. Each question item will be created for each correct answer   \n",
    "    question_items = []\n",
    "    for answer_item in correct_answer_items:\n",
    "        answer_item = answer_item.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_item)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionImgPath\": question_img_path, # Most important\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_flow_chart_completion(questionTask):\n",
    "    return parse_diagram_completion(questionTask)\n",
    "\n",
    "questionTask = load_yaml_file(cam11_test1_2)[\"question\"][1]\n",
    "# questionTask = load_yaml_file(cam11_test2_1)[\"question\"][2]\n",
    "print('Raw version')\n",
    "display(questionTask)\n",
    "print('Parsed version')\n",
    "parse_diagram_completion(questionTask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence, Summary and Note Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task_type': 'note_completion\\n',\n",
       " 'task_question_number': 'Questions 1-9\\n',\n",
       " 'task_description': 'Complete the notes below.\\nChoose ONE WORD ONLY from the passage for each answer.\\n\\nWrite your answers in boxes 1-9 on your answer sheet.\\n',\n",
       " 'question_main_title': 'The Early History of Cinnamon\\n',\n",
       " 'question_main_text': 'Biblical times:\\n\\nadded to 1..\\n\\nused to show 2. Between people\\n\\nAncient Rome:\\n\\nused for its sweet smell at 3..\\n\\nMiddle Ages:\\n\\nadded to food, especially meat\\n\\nwas an indication of a persons 4..\\n\\nknown as a treatment for 5.. and other health problems\\n\\ngrown in 6.\\n\\nmerchants used 7 to bring it to the Mediterranean\\n\\narrived in the Mediterranean at 8\\n\\ntraders took it to 9. and sold it to destinations around Europe.\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': '',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '1. oils\\n\\n2. friendship\\n\\n3. funerals\\n\\n4. wealth\\n\\n5. indigestion\\n\\n6. India\\n\\n7. camels\\n\\n8. Alexandria\\n\\n9. Venice\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'note_completion',\n",
       " 'taskQuestionNumberList': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'taskQuestionNumberText': 'Questions 1-9',\n",
       " 'taskDescription': 'Complete the notes below.\\nChoose ONE WORD ONLY from the passage for each answer.\\nWrite your answers in boxes 1-9 on your answer sheet.',\n",
       " 'questionMainTitle': 'The Early History of Cinnamon',\n",
       " 'questionMainText': 'Biblical times:\\nadded to 1..\\nused to show 2. Between people\\nAncient Rome:\\nused for its sweet smell at 3..\\nMiddle Ages:\\nadded to food, especially meat\\nwas an indication of a persons 4..\\nknown as a treatment for 5.. and other health problems\\ngrown in 6.\\nmerchants used 7 to bring it to the Mediterranean\\narrived in the Mediterranean at 8\\ntraders took it to 9. and sold it to destinations around Europe.',\n",
       " 'questionItems': [{'questionNumber': 1, 'correctAnswer': 'oils'},\n",
       "  {'questionNumber': 2, 'correctAnswer': 'friendship'},\n",
       "  {'questionNumber': 3, 'correctAnswer': 'funerals'},\n",
       "  {'questionNumber': 4, 'correctAnswer': 'wealth'},\n",
       "  {'questionNumber': 5, 'correctAnswer': 'indigestion'},\n",
       "  {'questionNumber': 6, 'correctAnswer': 'India'},\n",
       "  {'questionNumber': 7, 'correctAnswer': 'camels'},\n",
       "  {'questionNumber': 8, 'correctAnswer': 'Alexandria'},\n",
       "  {'questionNumber': 9, 'correctAnswer': 'Venice'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_sentence_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "    \n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_multiple_line(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_items = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Idea: Correct-answer-bassed question items. Each question item will be created for each correct answer   \n",
    "    question_items = []\n",
    "    for answer_item in correct_answer_items:\n",
    "        answer_item = answer_item.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_item)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_summary_completion(questionTask):\n",
    "    return parse_sentence_completion(questionTask)\n",
    "\n",
    "def parse_note_completion(questionTask):\n",
    "    return parse_sentence_completion(questionTask)\n",
    "    \n",
    "questionTask = load_yaml_file(cam13_test2_1)[\"question\"][0] # Note completion\n",
    "# questionTask = load_yaml_file(cam11_test2_2)[\"question\"][1] # Summary completion\n",
    "# questionTask = load_yaml_file(cam11_test1_1)[\"question\"][0] # Sentence completion\n",
    "print('Raw version')\n",
    "display(questionTask)\n",
    "print('Parsed version')\n",
    "parse_sentence_completion(questionTask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task_type': 'table_completion\\n',\n",
       " 'task_question_number': 'Questions 30-36\\n',\n",
       " 'task_description': 'Complete the table below.\\n\\nChoose ONE WORD from the passage for each answer.\\n\\nWrite your answers in boxes 30-36 on your answer sheet.\\n',\n",
       " 'question_main_title': 'GEO-ENGINEERING PROJECTS\\n',\n",
       " 'question_main_text': 'Procedure | Aim\\n\\nput a large number of tiny spacecraft into orbit far above Earth | to create a 30.. that would reduce the amount of light reaching Earth\\n\\nplace 31 in the sea | to encourage 32 to form\\n\\nrelease aerosol sprays into the stratosphere | to create 33. that would reduce the amount of light reaching Earth\\n\\nfix strong 34 to Greenland ice sheets | to prevent icebergs moving into the sea\\n\\nplant trees in Russian Arctic that would lose their leaves in winter | to allow the 35 to reflect radiation\\n\\nchange the direction of 36 | to bring more cold water into ice-forming areas\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': '',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '30. sunshade\\n\\n31. iron\\n\\n32. algae\\n\\n33. clouds\\n\\n34. cables\\n\\n35. snow\\n\\n36. rivers  \\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'table_completion',\n",
       " 'taskQuestionNumberList': [30, 31, 32, 33, 34, 35, 36],\n",
       " 'taskQuestionNumberText': 'Questions 30-36',\n",
       " 'taskDescription': 'Complete the table below.\\nChoose ONE WORD from the passage for each answer.\\nWrite your answers in boxes 30-36 on your answer sheet.',\n",
       " 'questionMainTitle': 'GEO-ENGINEERING PROJECTS',\n",
       " 'questionMainText': [('Procedure', 'Aim'),\n",
       "  ('put a large number of tiny spacecraft into orbit far above Earth',\n",
       "   'to create a 30.. that would reduce the amount of light reaching Earth'),\n",
       "  ('place 31 in the sea', 'to encourage 32 to form'),\n",
       "  ('release aerosol sprays into the stratosphere',\n",
       "   'to create 33. that would reduce the amount of light reaching Earth'),\n",
       "  ('fix strong 34 to Greenland ice sheets',\n",
       "   'to prevent icebergs moving into the sea'),\n",
       "  ('plant trees in Russian Arctic that would lose their leaves in winter',\n",
       "   'to allow the 35 to reflect radiation'),\n",
       "  ('change the direction of 36',\n",
       "   'to bring more cold water into ice-forming areas')],\n",
       " 'questionItems': [{'questionNumber': 30, 'correctAnswer': 'sunshade'},\n",
       "  {'questionNumber': 31, 'correctAnswer': 'iron'},\n",
       "  {'questionNumber': 32, 'correctAnswer': 'algae'},\n",
       "  {'questionNumber': 33, 'correctAnswer': 'clouds'},\n",
       "  {'questionNumber': 34, 'correctAnswer': 'cables'},\n",
       "  {'questionNumber': 35, 'correctAnswer': 'snow'},\n",
       "  {'questionNumber': 36, 'correctAnswer': 'rivers'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_table_completion(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_multiple_line(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    table_data_rows = [tuple(r.strip() for r in re.split(r'\\|',row)) for row in question_main_text_lines]\n",
    "\n",
    "\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    question_items = []\n",
    "    for answer_line in correct_answer_lines:\n",
    "        answer_line = answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": table_data_rows,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "questionTask = load_yaml_file(cam11_test1_3)[\"question\"][1]\n",
    "print('Raw version')\n",
    "display(questionTask)\n",
    "print('Parsed version')\n",
    "parse_table_completion(questionTask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'matching_features\\n',\n",
       " 'task_question_number': 'Questions 37-40\\n',\n",
       " 'task_description': 'Look at the following statements (Questions 37-40) and the list of scientists below.\\n\\nMatch each statement with the correct scientist, A-D.\\n\\nWrite the correct letter, A-D, in boxes 37-40 on your answer sheet.\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': '37   The effects of geo-engineering may not be long-lasting.\\n\\n38   Geo-engineering is a topic worth exploring.\\n\\n39   It may be necessary to limit the effectiveness of geo-engineering projects.\\n\\n40   Research into non-fossil-based fuels cannot be replaced by geo-engineering.\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': 'List of Scientists\\n',\n",
       " 'question_list_of_options': 'A    Roger Angel\\n\\nB    Phil Rasch\\n\\nC    Dan Lunt\\n\\nD    Martin Sommerkorn\\n',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '37. B\\n\\n38. D\\n\\n39. C\\n\\n40. A'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'matching_features',\n",
       " 'taskQuestionNumberList': [37, 38, 39, 40],\n",
       " 'taskQuestionNumberText': 'Questions 37-40',\n",
       " 'taskDescription': 'Look at the following statements (Questions 37-40) and the list of scientists below.\\nMatch each statement with the correct scientist, A-D.\\nWrite the correct letter, A-D, in boxes 37-40 on your answer sheet.',\n",
       " 'questionMainTitle': '',\n",
       " 'questionMainText': '37   The effects of geo-engineering may not be long-lasting.\\n38   Geo-engineering is a topic worth exploring.\\n39   It may be necessary to limit the effectiveness of geo-engineering projects.\\n40   Research into non-fossil-based fuels cannot be replaced by geo-engineering.',\n",
       " 'questionListTitle': 'List of Scientists',\n",
       " 'questionListOptions': [('A', 'Roger Angel'),\n",
       "  ('B', 'Phil Rasch'),\n",
       "  ('C', 'Dan Lunt'),\n",
       "  ('D', 'Martin Sommerkorn')],\n",
       " 'questionItems': [{'questionNumber': 37,\n",
       "   'questionText': 'The effects of geo-engineering may not be long-lasting.',\n",
       "   'questionOptions': [('A', 'Roger Angel'),\n",
       "    ('B', 'Phil Rasch'),\n",
       "    ('C', 'Dan Lunt'),\n",
       "    ('D', 'Martin Sommerkorn')],\n",
       "   'correctAnswer': 'B'},\n",
       "  {'questionNumber': 38,\n",
       "   'questionText': 'Geo-engineering is a topic worth exploring.',\n",
       "   'questionOptions': [('A', 'Roger Angel'),\n",
       "    ('B', 'Phil Rasch'),\n",
       "    ('C', 'Dan Lunt'),\n",
       "    ('D', 'Martin Sommerkorn')],\n",
       "   'correctAnswer': 'D'},\n",
       "  {'questionNumber': 39,\n",
       "   'questionText': 'It may be necessary to limit the effectiveness of geo-engineering projects.',\n",
       "   'questionOptions': [('A', 'Roger Angel'),\n",
       "    ('B', 'Phil Rasch'),\n",
       "    ('C', 'Dan Lunt'),\n",
       "    ('D', 'Martin Sommerkorn')],\n",
       "   'correctAnswer': 'C'},\n",
       "  {'questionNumber': 40,\n",
       "   'questionText': 'Research into non-fossil-based fuels cannot be replaced by geo-engineering.',\n",
       "   'questionOptions': [('A', 'Roger Angel'),\n",
       "    ('B', 'Phil Rasch'),\n",
       "    ('C', 'Dan Lunt'),\n",
       "    ('D', 'Martin Sommerkorn')],\n",
       "   'correctAnswer': 'A'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching questions\n",
    "def parse_matching_features(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_multiple_line(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "    # question_list_of_options_lines = re.split(r'\\n+', question_list_of_options)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_option_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: A    Roger Angel\\n\\nB    Phil Rasch\n",
    "\n",
    "\n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": question_option_items, # option is a tuple but correct answer might be a string\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "questionTask = load_yaml_file(cam11_test1_3)[\"question\"][2]\n",
    "# questionTask = load_yaml_file(cam11_test2_1)[\"question\"][1]\n",
    "\n",
    "display(questionTask)\n",
    "parse_matching_features(questionTask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'matching_headings\\n',\n",
       " 'task_question_number': 'Questions 14-20\\n',\n",
       " 'task_description': 'Reading Passage 2 has seven paragraphs, A-G.\\n\\nChoose the correct heading for each paragraph from the list of headings below.\\n\\nWrite the correct number, i-ix, in boxes 14-20 on your answer sheet.\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': '14    Paragraph A\\n\\n15    Paragraph B\\n\\n16    Paragraph C\\n\\n17    Paragraph D\\n\\n18    Paragraph E\\n\\n19    Paragraph F\\n\\n20    Paragraph G\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': 'List of Headings\\n',\n",
       " 'question_list_of_options': 'i    Evidence of innovative environment management practices\\n\\nii    An undisputed answer to a question about the moai\\n\\niii    The future of the moai statues\\n\\niv    A theory which supports a local belief\\n\\nv    The future of Easter Island\\n\\nvi    Two opposing views about the Rapanui people\\n\\nvii    Destruction outside the inhabitants control\\n\\nviii    How the statues made a situation worse\\n\\nix    Diminishing food resources\\n',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '14. ii\\n\\n15. ix\\n\\n16. viii\\n\\n17. i\\n\\n18. iv\\n\\n19. vii\\n\\n20. vi\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'matching_headings',\n",
       " 'taskQuestionNumberList': [14, 15, 16, 17, 18, 19, 20],\n",
       " 'taskQuestionNumberText': 'Questions 14-20',\n",
       " 'taskDescription': 'Reading Passage 2 has seven paragraphs, A-G.\\nChoose the correct heading for each paragraph from the list of headings below.\\nWrite the correct number, i-ix, in boxes 14-20 on your answer sheet.',\n",
       " 'questionMainTitle': '',\n",
       " 'questionMainText': '14    Paragraph A\\n15    Paragraph B\\n16    Paragraph C\\n17    Paragraph D\\n18    Paragraph E\\n19    Paragraph F\\n20    Paragraph G',\n",
       " 'questionListTitle': 'List of Headings',\n",
       " 'questionListOptions': [('i',\n",
       "   'Evidence of innovative environment management practices'),\n",
       "  ('ii', 'An undisputed answer to a question about the moai'),\n",
       "  ('iii', 'The future of the moai statues'),\n",
       "  ('iv', 'A theory which supports a local belief'),\n",
       "  ('v', 'The future of Easter Island'),\n",
       "  ('vi', 'Two opposing views about the Rapanui people'),\n",
       "  ('vii', 'Destruction outside the inhabitants control'),\n",
       "  ('viii', 'How the statues made a situation worse'),\n",
       "  ('ix', 'Diminishing food resources')],\n",
       " 'questionItems': [{'questionNumber': 14,\n",
       "   'questionText': 'Paragraph A',\n",
       "   'questionOptions': [('i',\n",
       "     'Evidence of innovative environment management practices'),\n",
       "    ('ii', 'An undisputed answer to a question about the moai'),\n",
       "    ('iii', 'The future of the moai statues'),\n",
       "    ('iv', 'A theory which supports a local belief'),\n",
       "    ('v', 'The future of Easter Island'),\n",
       "    ('vi', 'Two opposing views about the Rapanui people'),\n",
       "    ('vii', 'Destruction outside the inhabitants control'),\n",
       "    ('viii', 'How the statues made a situation worse'),\n",
       "    ('ix', 'Diminishing food resources')],\n",
       "   'correctAnswer': 'ii'},\n",
       "  {'questionNumber': 15,\n",
       "   'questionText': 'Paragraph B',\n",
       "   'questionOptions': [('i',\n",
       "     'Evidence of innovative environment management practices'),\n",
       "    ('ii', 'An undisputed answer to a question about the moai'),\n",
       "    ('iii', 'The future of the moai statues'),\n",
       "    ('iv', 'A theory which supports a local belief'),\n",
       "    ('v', 'The future of Easter Island'),\n",
       "    ('vi', 'Two opposing views about the Rapanui people'),\n",
       "    ('vii', 'Destruction outside the inhabitants control'),\n",
       "    ('viii', 'How the statues made a situation worse'),\n",
       "    ('ix', 'Diminishing food resources')],\n",
       "   'correctAnswer': 'ix'},\n",
       "  {'questionNumber': 16,\n",
       "   'questionText': 'Paragraph C',\n",
       "   'questionOptions': [('i',\n",
       "     'Evidence of innovative environment management practices'),\n",
       "    ('ii', 'An undisputed answer to a question about the moai'),\n",
       "    ('iii', 'The future of the moai statues'),\n",
       "    ('iv', 'A theory which supports a local belief'),\n",
       "    ('v', 'The future of Easter Island'),\n",
       "    ('vi', 'Two opposing views about the Rapanui people'),\n",
       "    ('vii', 'Destruction outside the inhabitants control'),\n",
       "    ('viii', 'How the statues made a situation worse'),\n",
       "    ('ix', 'Diminishing food resources')],\n",
       "   'correctAnswer': 'viii'},\n",
       "  {'questionNumber': 17,\n",
       "   'questionText': 'Paragraph D',\n",
       "   'questionOptions': [('i',\n",
       "     'Evidence of innovative environment management practices'),\n",
       "    ('ii', 'An undisputed answer to a question about the moai'),\n",
       "    ('iii', 'The future of the moai statues'),\n",
       "    ('iv', 'A theory which supports a local belief'),\n",
       "    ('v', 'The future of Easter Island'),\n",
       "    ('vi', 'Two opposing views about the Rapanui people'),\n",
       "    ('vii', 'Destruction outside the inhabitants control'),\n",
       "    ('viii', 'How the statues made a situation worse'),\n",
       "    ('ix', 'Diminishing food resources')],\n",
       "   'correctAnswer': 'i'},\n",
       "  {'questionNumber': 18,\n",
       "   'questionText': 'Paragraph E',\n",
       "   'questionOptions': [('i',\n",
       "     'Evidence of innovative environment management practices'),\n",
       "    ('ii', 'An undisputed answer to a question about the moai'),\n",
       "    ('iii', 'The future of the moai statues'),\n",
       "    ('iv', 'A theory which supports a local belief'),\n",
       "    ('v', 'The future of Easter Island'),\n",
       "    ('vi', 'Two opposing views about the Rapanui people'),\n",
       "    ('vii', 'Destruction outside the inhabitants control'),\n",
       "    ('viii', 'How the statues made a situation worse'),\n",
       "    ('ix', 'Diminishing food resources')],\n",
       "   'correctAnswer': 'iv'},\n",
       "  {'questionNumber': 19,\n",
       "   'questionText': 'Paragraph F',\n",
       "   'questionOptions': [('i',\n",
       "     'Evidence of innovative environment management practices'),\n",
       "    ('ii', 'An undisputed answer to a question about the moai'),\n",
       "    ('iii', 'The future of the moai statues'),\n",
       "    ('iv', 'A theory which supports a local belief'),\n",
       "    ('v', 'The future of Easter Island'),\n",
       "    ('vi', 'Two opposing views about the Rapanui people'),\n",
       "    ('vii', 'Destruction outside the inhabitants control'),\n",
       "    ('viii', 'How the statues made a situation worse'),\n",
       "    ('ix', 'Diminishing food resources')],\n",
       "   'correctAnswer': 'vii'},\n",
       "  {'questionNumber': 20,\n",
       "   'questionText': 'Paragraph G',\n",
       "   'questionOptions': [('i',\n",
       "     'Evidence of innovative environment management practices'),\n",
       "    ('ii', 'An undisputed answer to a question about the moai'),\n",
       "    ('iii', 'The future of the moai statues'),\n",
       "    ('iv', 'A theory which supports a local belief'),\n",
       "    ('v', 'The future of Easter Island'),\n",
       "    ('vi', 'Two opposing views about the Rapanui people'),\n",
       "    ('vii', 'Destruction outside the inhabitants control'),\n",
       "    ('viii', 'How the statues made a situation worse'),\n",
       "    ('ix', 'Diminishing food resources')],\n",
       "   'correctAnswer': 'vi'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionTask = load_yaml_file(cam11_test2_2)[\"question\"][0]\n",
    "display(questionTask)\n",
    "\n",
    "def parse_matching_headings(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "    # question_list_of_options_lines = re.split(r'\\n+', question_list_of_options)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_option_item_pattern = re.compile(r'([ixv]+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: A    Roger Angel\\n\\nB    Phil Rasch\n",
    "\n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "\n",
    "parse_matching_headings(questionTask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'matching_paragraphs\\n',\n",
       " 'task_question_number': 'Questions 14-17\\n',\n",
       " 'task_description': 'Reading Passage 2 has six section, A-F.\\n\\nWhich paragraph contains the following information?\\n\\nWrite the correct letter, A-F, in boxes 14-17 on your answer sheet.\\n\\nNB  You may use any letter more than once.\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': '14   reference to research showing the beneficial effects of oxytocin on people\\n\\n15   reasons why the effects of oxytocin are complex\\n\\n16   mention of a period in which oxytocin attracted little scientific attention\\n\\n17   reference to people ignoring certain aspects of their research data\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': 'A-F\\n',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '14. B\\n\\n15. F\\n\\n16. B\\n\\n17. E\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'matching_paragraphs',\n",
       " 'taskQuestionNumberList': [14, 15, 16, 17],\n",
       " 'taskQuestionNumberText': 'Questions 14-17',\n",
       " 'taskDescription': 'Reading Passage 2 has six section, A-F.\\nWhich paragraph contains the following information?\\nWrite the correct letter, A-F, in boxes 14-17 on your answer sheet.\\nNB  You may use any letter more than once.',\n",
       " 'questionMainTitle': '',\n",
       " 'questionMainText': '14   reference to research showing the beneficial effects of oxytocin on people\\n15   reasons why the effects of oxytocin are complex\\n16   mention of a period in which oxytocin attracted little scientific attention\\n17   reference to people ignoring certain aspects of their research data',\n",
       " 'questionListTitle': '',\n",
       " 'questionListOptions': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
       " 'questionItems': [{'questionNumber': 14,\n",
       "   'questionOptions': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
       "   'correctAnswer': 'B'},\n",
       "  {'questionNumber': 15,\n",
       "   'questionOptions': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
       "   'correctAnswer': 'F'},\n",
       "  {'questionNumber': 16,\n",
       "   'questionOptions': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
       "   'correctAnswer': 'B'},\n",
       "  {'questionNumber': 17,\n",
       "   'questionOptions': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
       "   'correctAnswer': 'E'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionTask = load_yaml_file(cam13_test2_2)[\"question\"][0]\n",
    "display(questionTask)\n",
    "\n",
    "def parse_matching_paragraphs(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    question_list_of_options = clean_text_multiple_line(question_list_of_options)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    start_char, end_char = re.split('-', question_list_of_options)\n",
    "    question_option_items = list_AZ(start_char, end_char)\n",
    "    #  Strip items\n",
    "\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    \n",
    "    question_items = []\n",
    "    for answer_line in correct_answer_lines:\n",
    "        answer_line = answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "parse_matching_paragraphs(questionTask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Sentence Endings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'matching_sentence_endings\\n',\n",
       " 'task_question_number': 'Questions 38-40\\n',\n",
       " 'task_description': 'Complete each sentence with the correct ending, A, B, C or D below.\\n\\nWrite the correct letter, A, B, C or D, in boxes 38-40 on your answer sheet.\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': '38   If there are any trend-related changes impacting on your category, you should\\n\\n39   If a current trend highlights a negative aspect of your category, you should\\n\\n40   If the consumers new focus has an increasing lack of connection with your offering you should\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': 'A   employ a combination of strategies to maintain your consumer base.\\n\\nB   identify the most appropriate innovation strategy to use.\\n\\nC   emphasise your brands traditional values with the counteract-and-affirm strategy.\\n\\nD   use the combine-and-transcend strategy to integrate the two worlds.\\n',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '38. B\\n\\n39. C\\n\\n40. D'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'matching_sentence_endings',\n",
       " 'taskQuestionNumberList': [38, 39, 40],\n",
       " 'taskQuestionNumberText': 'Questions 38-40',\n",
       " 'taskDescription': 'Complete each sentence with the correct ending, A, B, C or D below.\\nWrite the correct letter, A, B, C or D, in boxes 38-40 on your answer sheet.',\n",
       " 'questionMainTitle': '',\n",
       " 'questionMainText': '38   If there are any trend-related changes impacting on your category, you should\\n39   If a current trend highlights a negative aspect of your category, you should\\n40   If the consumers new focus has an increasing lack of connection with your offering you should',\n",
       " 'questionListTitle': '',\n",
       " 'questionListOptions': [('A',\n",
       "   'employ a combination of strategies to maintain your consumer base.'),\n",
       "  ('B', 'identify the most appropriate innovation strategy to use.'),\n",
       "  ('C',\n",
       "   'emphasise your brands traditional values with the counteract-and-affirm strategy.'),\n",
       "  ('D',\n",
       "   'use the combine-and-transcend strategy to integrate the two worlds.')],\n",
       " 'questionItems': [{'questionNumber': 38,\n",
       "   'questionOptions': [('A',\n",
       "     'employ a combination of strategies to maintain your consumer base.'),\n",
       "    ('B', 'identify the most appropriate innovation strategy to use.'),\n",
       "    ('C',\n",
       "     'emphasise your brands traditional values with the counteract-and-affirm strategy.'),\n",
       "    ('D',\n",
       "     'use the combine-and-transcend strategy to integrate the two worlds.')],\n",
       "   'correctAnswer': 'B'},\n",
       "  {'questionNumber': 39,\n",
       "   'questionOptions': [('A',\n",
       "     'employ a combination of strategies to maintain your consumer base.'),\n",
       "    ('B', 'identify the most appropriate innovation strategy to use.'),\n",
       "    ('C',\n",
       "     'emphasise your brands traditional values with the counteract-and-affirm strategy.'),\n",
       "    ('D',\n",
       "     'use the combine-and-transcend strategy to integrate the two worlds.')],\n",
       "   'correctAnswer': 'C'},\n",
       "  {'questionNumber': 40,\n",
       "   'questionOptions': [('A',\n",
       "     'employ a combination of strategies to maintain your consumer base.'),\n",
       "    ('B', 'identify the most appropriate innovation strategy to use.'),\n",
       "    ('C',\n",
       "     'emphasise your brands traditional values with the counteract-and-affirm strategy.'),\n",
       "    ('D',\n",
       "     'use the combine-and-transcend strategy to integrate the two worlds.')],\n",
       "   'correctAnswer': 'D'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionTask = load_yaml_file(cam13_test2_3)[\"question\"][2]\n",
    "display(questionTask)\n",
    "\n",
    "def parse_matching_sentence_endings(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    question_list_of_options = clean_text_multiple_line(question_list_of_options)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    question_option_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    #  Strip items\n",
    "\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    \n",
    "    question_items = []\n",
    "    for answer_line in correct_answer_lines:\n",
    "        answer_line = answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "parse_matching_sentence_endings(questionTask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Completion Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'summary_completion_word_list\\n',\n",
       " 'task_question_number': 'Questions 31-33\\n',\n",
       " 'task_description': 'Complete the summary using the list of words, A-H, below.\\n\\nWrite the correct letters, A-H, in boxes 31-33 on your answer sheet.\\n',\n",
       " 'question_main_title': 'Art and the Brain\\n',\n",
       " 'question_main_text': 'The discipline of neuroaesthetics aims to bring scientific objectivity to the study of art. Neurological studies of the brain, for example, demonstrate the impact which Impressionist paintings have on our 31. Alex Forsythe of the University of Liverpool believes many artists give their works the precise degree of 32 which most appeals to the viewers brain. She also observes that pleasing works of art often contain certain repeated 33 which occur frequently in the natural world.\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': 'A     interpretation      \\n\\nB     complexity            \\n\\nC     emotions\\n\\nD     movements         \\n\\nE     skill                       \\n\\nF     layout\\n\\nG     concern                \\n\\nH     images\\n',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '31. C\\n\\n32. B\\n\\n33. H\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'summary_completion_word_list',\n",
       " 'taskQuestionNumberList': [31, 32, 33],\n",
       " 'taskQuestionNumberText': 'Questions 31-33',\n",
       " 'taskDescription': 'Complete the summary using the list of words, A-H, below.\\nWrite the correct letters, A-H, in boxes 31-33 on your answer sheet.',\n",
       " 'questionMainTitle': 'Art and the Brain',\n",
       " 'questionMainText': 'The discipline of neuroaesthetics aims to bring scientific objectivity to the study of art. Neurological studies of the brain, for example, demonstrate the impact which Impressionist paintings have on our 31. Alex Forsythe of the University of Liverpool believes many artists give their works the precise degree of 32 which most appeals to the viewers brain. She also observes that pleasing works of art often contain certain repeated 33 which occur frequently in the natural world.',\n",
       " 'questionListTitle': '',\n",
       " 'questionListOptions': [('A', 'interpretation'),\n",
       "  ('B', 'complexity'),\n",
       "  ('C', 'emotions'),\n",
       "  ('D', 'movements'),\n",
       "  ('E', 'skill'),\n",
       "  ('F', 'layout'),\n",
       "  ('G', 'concern'),\n",
       "  ('H', 'images')],\n",
       " 'questionItems': [{'questionNumber': 31,\n",
       "   'questionOptions': [('A', 'interpretation'),\n",
       "    ('B', 'complexity'),\n",
       "    ('C', 'emotions'),\n",
       "    ('D', 'movements'),\n",
       "    ('E', 'skill'),\n",
       "    ('F', 'layout'),\n",
       "    ('G', 'concern'),\n",
       "    ('H', 'images')],\n",
       "   'correctAnswer': 'C'},\n",
       "  {'questionNumber': 32,\n",
       "   'questionOptions': [('A', 'interpretation'),\n",
       "    ('B', 'complexity'),\n",
       "    ('C', 'emotions'),\n",
       "    ('D', 'movements'),\n",
       "    ('E', 'skill'),\n",
       "    ('F', 'layout'),\n",
       "    ('G', 'concern'),\n",
       "    ('H', 'images')],\n",
       "   'correctAnswer': 'B'},\n",
       "  {'questionNumber': 33,\n",
       "   'questionOptions': [('A', 'interpretation'),\n",
       "    ('B', 'complexity'),\n",
       "    ('C', 'emotions'),\n",
       "    ('D', 'movements'),\n",
       "    ('E', 'skill'),\n",
       "    ('F', 'layout'),\n",
       "    ('G', 'concern'),\n",
       "    ('H', 'images')],\n",
       "   'correctAnswer': 'H'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionTask = load_yaml_file(cam11_test2_3)[\"question\"][1]\n",
    "display(questionTask)\n",
    "\n",
    "def parse_summary_completion_word_list(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    question_list_of_options = clean_text_multiple_line(question_list_of_options)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    \n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    question_option_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') \n",
    "    question_option_items = question_option_item_pattern.findall(question_list_of_options)\n",
    "    #  Strip items\n",
    "\n",
    "    # Idea: Each matching question item contains question, list of choices and correct answer\n",
    "    \n",
    "    question_items = []\n",
    "    for answer_line in correct_answer_lines:\n",
    "        answer_line = answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = answer_item_match.group(1).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionListTitle\": question_list_title,\n",
    "        \"questionListOptions\": question_option_items,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "parse_summary_completion_word_list(questionTask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True False Not Given & Yes No Not Given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'true_false_notgiven\\n',\n",
       " 'task_question_number': 'Questions 8-13\\n',\n",
       " 'task_description': 'Do the following statements agree with the information given in Reading Passage?\\n\\nIn boxes 8-13 on your answer sheet, write\\n\\nTRUE               if the statement agrees with the information\\n\\nFALSE              if the statement contradicts the information\\n\\nNOT GIVEN    if there is no information on this\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': '8   Methods for predicting the Earths population have recently changed.\\n\\n9   Human beings are responsible for some of the destruction to food-producing land.\\n\\n10   The crops produced in vertical farms will depend on the season.\\n\\n11   Some damage to food crops is caused by climate change.\\n\\n12   Fertilisers will be needed for certain crops in vertical farms.\\n\\n13   Vertical farming will make plants less likely to be affected by infectious diseases.\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': '',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '8. NOT GIVEN\\n\\n9. TRUE\\n\\n10. FALSE\\n\\n11. TRUE\\n\\n12. FALSE\\n\\n13. TRUE'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'true_false_notgiven',\n",
       " 'taskQuestionNumberList': [8, 9, 10, 11, 12, 13],\n",
       " 'taskQuestionNumberText': 'Questions 8-13',\n",
       " 'taskDescription': 'Do the following statements agree with the information given in Reading Passage?\\nIn boxes 8-13 on your answer sheet, write\\nTRUE               if the statement agrees with the information\\nFALSE              if the statement contradicts the information\\nNOT GIVEN    if there is no information on this',\n",
       " 'questionMainTitle': '',\n",
       " 'questionMainText': '8   Methods for predicting the Earths population have recently changed.\\n9   Human beings are responsible for some of the destruction to food-producing land.\\n10   The crops produced in vertical farms will depend on the season.\\n11   Some damage to food crops is caused by climate change.\\n12   Fertilisers will be needed for certain crops in vertical farms.\\n13   Vertical farming will make plants less likely to be affected by infectious diseases.',\n",
       " 'questionItems': [{'questionNumber': 8,\n",
       "   'questionText': 'Methods for predicting the Earths population have recently changed.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'NOT GIVEN'},\n",
       "  {'questionNumber': 9,\n",
       "   'questionText': 'Human beings are responsible for some of the destruction to food-producing land.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'TRUE'},\n",
       "  {'questionNumber': 10,\n",
       "   'questionText': 'The crops produced in vertical farms will depend on the season.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'FALSE'},\n",
       "  {'questionNumber': 11,\n",
       "   'questionText': 'Some damage to food crops is caused by climate change.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'TRUE'},\n",
       "  {'questionNumber': 12,\n",
       "   'questionText': 'Fertilisers will be needed for certain crops in vertical farms.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'FALSE'},\n",
       "  {'questionNumber': 13,\n",
       "   'questionText': 'Vertical farming will make plants less likely to be affected by infectious diseases.',\n",
       "   'questionOptions': ['TRUE', 'FALSE', 'NOT GIVEN'],\n",
       "   'correctAnswer': 'TRUE'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_true_false_not_given(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "\n",
    "    # Idea: Each TFNG question item contains question, list of choices (TFNG) and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": [\"TRUE\", \"FALSE\", \"NOT GIVEN\"], # Always the same\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "def parse_yes_no_not_given(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    correct_answer = clean_text_multiple_line(correct_answer)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "\n",
    "    # Split items\n",
    "    question_main_text_lines = re.split(r'\\n+', question_main_text)\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "\n",
    "    # Matching patterns - both questions and correct answers\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "    question_item_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 8. NOT GIVEN\\n\\n9. TRUE\\n\\n\n",
    "\n",
    "    # Idea: Each TFNG question item contains question, list of choices (TFNG) and correct answer\n",
    "    question_items = []\n",
    "    for question_line, answer_line in zip(question_main_text_lines, correct_answer_lines):\n",
    "        question_line, answer_line = question_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = question_item_pattern.match(question_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": [\"YES\", \"NO\", \"NOT GIVEN\"], # Always the same\n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionMainTitle\": question_main_title,\n",
    "        \"questionMainText\": question_main_text,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "questionTask = load_yaml_file(cam11_test1_1)[\"question\"][1] # TFNG\n",
    "# questionTask = load_yaml_file(cam11_test2_3)[\"question\"][2] # Yes no not given\n",
    "display(questionTask)\n",
    "parse_true_false_not_given(questionTask)\n",
    "# parse_yes_no_not_given(questionTask)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Choice Select Many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'multiple_choice_select_many\\n',\n",
       " 'task_question_number': 'Questions 25 and 26\\n',\n",
       " 'task_description': 'Choose TWO letters, A-E.\\n\\nWrite the correct letters in boxes 25 and 26 on your answer sheet.\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': 'On what points do Hunt and Lipo disagree with Diamond?\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': 'A   the period when the moai were created\\n\\nB   how the moai were transported\\n\\nC   the impact of the moai on Rapanui society\\n\\nD   how the moai were carved\\n\\nE   the origins of the people who made the moai\\n',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '25. B\\n\\n26. C\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'multiple_choice_select_many',\n",
       " 'taskQuestionNumberList': [25, 26],\n",
       " 'taskQuestionNumberText': 'Questions 25 and 26',\n",
       " 'taskDescription': 'Choose TWO letters, A-E.\\nWrite the correct letters in boxes 25 and 26 on your answer sheet.',\n",
       " 'questionMainTitle': '',\n",
       " 'questionMainText': 'On what points do Hunt and Lipo disagree with Diamond?',\n",
       " 'questionItems': [('A', 'the period when the moai were created'),\n",
       "  ('B', 'how the moai were transported'),\n",
       "  ('C', 'the impact of the moai on Rapanui society'),\n",
       "  ('D', 'how the moai were carved'),\n",
       "  ('E', 'the origins of the people who made the moai')],\n",
       " 'correctAnswer': ['B', 'C']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def parse_multiple_choice_select_many(questionTask):\n",
    "    # Task description\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    # matching patterns\n",
    "    correct_answer_pattern = re.compile(r'\\d+[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    question_item_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer)\n",
    "    question_list_of_options_lines = re.split(r'\\n+', question_list_of_options)\n",
    "\n",
    "\n",
    "    question_items =  question_item_pattern.findall(question_list_of_options)\n",
    "    correct_answer = correct_answer_pattern.findall(correct_answer)\n",
    "\n",
    "    return {\n",
    "    \"taskType\": task_type,\n",
    "    \"taskQuestionNumberList\": task_question_number_list,\n",
    "    \"taskQuestionNumberText\": task_question_number,\n",
    "    \"taskDescription\": task_description,\n",
    "    \"questionMainTitle\": question_main_title,\n",
    "    \"questionMainText\": question_main_text,\n",
    "    \"questionItems\": question_items,\n",
    "    \"correctAnswer\": correct_answer\n",
    "    }\n",
    "\n",
    "questionTask = load_yaml_file(cam11_test2_2)[\"question\"][2]\n",
    "display(questionTask)\n",
    "parse_multiple_choice_select_many(questionTask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Choice Select One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'multiple_choice_select_one\\n',\n",
       " 'task_question_number': 'Questions 27-30\\n',\n",
       " 'task_description': 'Choose the correct letter, A, B, C or D.\\n\\nWrite the correct letter in boxes 27-30 on your answer sheet\\n',\n",
       " 'question_main_title': '',\n",
       " 'question_main_text': '27    In the second paragraph, the writer refers to a shape-matching test in order to illustrate\\n\\nA   the subjective nature of art appreciation.\\n\\nB   the reliance of modern art on abstract forms.\\n\\nC   our tendency to be influenced by the opinions of others.\\n\\nD   a common problem encountered when processing visual data.\\n\\n\\n\\n28   Angelina Hawley-Dolans findings indicate that people\\n\\nA   mostly favour works of art which they know well.\\n\\nB   hold fixed ideas about what makes a good work of art.\\n\\nC   are often misled by their initial expectations of a work of art.\\n\\nD   have the ability to perceive the intention behind works of art.\\n\\n\\n29    Results of studies involving Robert Pepperells pieces suggest that people\\n\\nA   can appreciate a painting without fully understanding it.\\n\\nB   find it satisfying to work out what a painting represents.\\n\\nC   vary widely in the time they spend looking at paintings.\\n\\nD   generally prefer representational art to abstract art.\\n\\n\\n\\n30   What do the experiments described in the fifth paragraph suggest about the paintings of Mondrian?\\n\\nA   They are more carefully put together than they appear.\\n\\nB   They can be interpreted in a number of different ways.\\n\\nC   They challenge our assumptions about shape and colour.\\n\\nD   They are easier to appreciate than many other abstract works.\\n',\n",
       " 'question_img_path': '',\n",
       " 'question_list_title': '',\n",
       " 'question_list_of_options': '',\n",
       " 'example_answer': '',\n",
       " 'correct_answer': '27. C\\n\\n28. D\\n\\n29. B\\n\\n30. A\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'taskType': 'multiple_choice_select_one',\n",
       " 'taskQuestionNumberList': [27, 28, 29, 30],\n",
       " 'taskQuestionNumberText': 'Questions 27-30',\n",
       " 'taskDescription': 'Choose the correct letter, A, B, C or D.\\nWrite the correct letter in boxes 27-30 on your answer sheet',\n",
       " 'questionItems': [{'questionNumber': 27,\n",
       "   'questionText': 'In the second paragraph, the writer refers to a shape-matching test in order to illustrate',\n",
       "   'questionOptions': [('A', 'the subjective nature of art appreciation.'),\n",
       "    ('B', 'the reliance of modern art on abstract forms.'),\n",
       "    ('C', 'our tendency to be influenced by the opinions of others.'),\n",
       "    ('D', 'a common problem encountered when processing visual data.')],\n",
       "   'correctAnswer': 'C'},\n",
       "  {'questionNumber': 28,\n",
       "   'questionText': 'Angelina Hawley-Dolans findings indicate that people',\n",
       "   'questionOptions': [('A',\n",
       "     'mostly favour works of art which they know well.'),\n",
       "    ('B', 'hold fixed ideas about what makes a good work of art.'),\n",
       "    ('C', 'are often misled by their initial expectations of a work of art.'),\n",
       "    ('D', 'have the ability to perceive the intention behind works of art.')],\n",
       "   'correctAnswer': 'D'},\n",
       "  {'questionNumber': 29,\n",
       "   'questionText': 'Results of studies involving Robert Pepperells pieces suggest that people',\n",
       "   'questionOptions': [('A',\n",
       "     'can appreciate a painting without fully understanding it.'),\n",
       "    ('B', 'find it satisfying to work out what a painting represents.'),\n",
       "    ('C', 'vary widely in the time they spend looking at paintings.'),\n",
       "    ('D', 'generally prefer representational art to abstract art.')],\n",
       "   'correctAnswer': 'B'},\n",
       "  {'questionNumber': 30,\n",
       "   'questionText': 'What do the experiments described in the fifth paragraph suggest about the paintings of Mondrian?',\n",
       "   'questionOptions': [('A',\n",
       "     'They are more carefully put together than they appear.'),\n",
       "    ('B', 'They can be interpreted in a number of different ways.'),\n",
       "    ('C', 'They challenge our assumptions about shape and colour.'),\n",
       "    ('D', 'They are easier to appreciate than many other abstract works.')],\n",
       "   'correctAnswer': 'A'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionTask = load_yaml_file(cam11_test2_3)[\"question\"][0]\n",
    "display(questionTask)\n",
    "\n",
    "def parse_multiple_choice_select_one(questionTask):\n",
    "    task_type = questionTask['task_type'].strip()\n",
    "    task_description = questionTask['task_description'].strip()\n",
    "    task_question_number = questionTask['task_question_number'].strip()\n",
    "\n",
    "    # Main content\n",
    "    question_main_title = questionTask['question_main_title'].strip()\n",
    "    question_main_text = questionTask['question_main_text'].strip()\n",
    "    correct_answer = questionTask['correct_answer'].strip()\n",
    "    question_list_title = questionTask['question_list_title'].strip()\n",
    "\n",
    "    # Not applicable but included for consistency\n",
    "    question_list_of_options = questionTask['question_list_of_options'].strip()\n",
    "    question_img_path = questionTask['question_img_path'].strip()\n",
    "    example_answer = questionTask['example_answer'].strip()\n",
    "\n",
    "    #  Clean text\n",
    "    task_description = clean_text_multiple_line(task_description)\n",
    "    question_main_title = clean_text_single_line(question_main_title)\n",
    "    question_main_text = clean_text_paragraph(question_main_text)\n",
    "    question_list_title = clean_text_single_line(question_list_title)\n",
    "    task_question_number_list = parse_task_question_number(task_question_number)\n",
    "\n",
    "    mcq_question_content_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "    mcq_question_option_pattern = re.compile(r'([A-Z])[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: A    Roger Angel\\n\\nB    Phil Rasch\n",
    "    correct_answer_pattern = re.compile(r'(\\d+)[^a-zA-Z\\d\\(\\)\\-\\+:]+(.*)') # Ex: 1. tomatoes 2. urban centres/ centers\n",
    "\n",
    "    # Split items\n",
    "    multiple_choice_question_item_lines = re.split(r'\\n(?=\\d+\\s)', question_main_text) # ['27    In the secon...\\nA   the subject...\\nB   the subject...', '28    The author...\\nA   the subject...\\nB   the subject...']\n",
    "    correct_answer_lines = re.split(r'\\n+', correct_answer) # ['27. A', '28. B']\n",
    "\n",
    "    question_items = []\n",
    "    for mcq_question_item_line, answer_line in zip(multiple_choice_question_item_lines, correct_answer_lines):\n",
    "        mcq_question_item_line, answer_line = mcq_question_item_line.strip(), answer_line.strip()\n",
    "\n",
    "        # Extract question number and correct answer for each question item\n",
    "        question_item_match = mcq_question_content_pattern.match(mcq_question_item_line)\n",
    "        question_option_items = mcq_question_option_pattern.findall(mcq_question_item_line)\n",
    "        answer_item_match = correct_answer_pattern.match(answer_line)\n",
    "\n",
    "        question_number = question_item_match.group(1).strip()\n",
    "        question_text = question_item_match.group(2).strip()\n",
    "        correct_answer = answer_item_match.group(2).strip()\n",
    "        question_items.append({\n",
    "            \"questionNumber\": int(question_number),\n",
    "            \"questionText\": question_text,\n",
    "            \"questionOptions\": question_option_items, \n",
    "            \"correctAnswer\": correct_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"taskType\": task_type,\n",
    "        \"taskQuestionNumberList\": task_question_number_list,\n",
    "        \"taskQuestionNumberText\": task_question_number,\n",
    "        \"taskDescription\": task_description,\n",
    "        \"questionItems\": question_items,\n",
    "    }\n",
    "\n",
    "parse_multiple_choice_select_one(questionTask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
